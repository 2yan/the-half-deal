{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3 \n",
    "import sql_tools\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "pick = sql_tools.IcePick(sqlite3, 'trade_history.sqlite')\n",
    "con = sqlite3.connect('trade_history.sqlite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_updates(tickers):\n",
    "    updates = pd.DataFrame(index = set(tickers))\n",
    "    updates['Last Updated'] = datetime(2018,1,24)\n",
    "    updates.index.name = 'Ticker'\n",
    "    updates.to_sql('symbol_info', con, if_exists='replace')\n",
    "\n",
    "\n",
    "def add_to_history(ticker, data):\n",
    "    try:\n",
    "        data.to_sql(ticker, con,if_exists= 'fail')\n",
    "    except ValueError:\n",
    "        latest_date = pick.get_data('AMD', ['Date']).max().loc[0]\n",
    "        downloaded_earliest = data['Date'].min()\n",
    "        for days in \n",
    "    return \n",
    "\n",
    "def load_from_history(ticker, columns = ['*']):\n",
    "    #if 'Date' not in columns:\n",
    "    #    columns.append('Date')\n",
    "    data = pick.get_data(ticker, columns).set_index('Date')\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    return data\n",
    "\n",
    "def get_history_list():\n",
    "    data = pick.read_sql('select ticker from symbol_info')['Ticker']\n",
    "    return data\n",
    "\n",
    "def is_in_history(ticker):\n",
    "    if ticker in history_list:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "history_list = get_history_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tickers():\n",
    "    nyse = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NYSE&render=download')\n",
    "    nasdaq = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download')\n",
    "    data = nyse.append(nasdaq)\n",
    "    data['Symbol']= data['Symbol'].str.replace(' ', '')\n",
    "    data = data.set_index('Symbol')\n",
    "    data = data[~data.index.duplicated()]\n",
    "    data = data[~data.index.str.contains('\\^')]\n",
    "    data = data[~data.index.str.contains('\\.')]\n",
    "    data = data[~data.index.str.contains('\\~')]\n",
    "    data = data[data['MarketCap'] > 0]\n",
    "    del data['Unnamed: 9']\n",
    "    return data\n",
    "tickers = get_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exponential_backoff(ticker, *args):\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            print('Trying to Download: {}'.format(ticker))\n",
    "            data = pdr.DataReader(ticker, 'yahoo', *args)\n",
    "            return data\n",
    "        except pdr.base.RemoteDataError as e:\n",
    "            i = i + 1\n",
    "            print(e)\n",
    "            print('Error {} : Exponential Backoff time: {}'.format(i , i**2))\n",
    "            \n",
    "            if i > 7:\n",
    "                print('Error Got too big, raising it')\n",
    "                raise e \n",
    "            time.sleep(i ** 2)\n",
    "def download_symbol(ticker):\n",
    "    ticker = ticker.upper()\n",
    "    print('Request is for {}'.format(ticker))\n",
    "    \n",
    "    if is_in_history(ticker):\n",
    "        print('Ticker In Current Data.')\n",
    "        data = load_from_history(ticker)\n",
    "        index = data[~data.index.isnull()].index\n",
    "        max_date = index.max()\n",
    "        print('Max Date of data: {}'.format(max_date))\n",
    "        print('Today: {}'.format(pd.to_datetime(datetime.today().strftime('%Y-%m-%d'))))\n",
    "        \n",
    "        if max_date == pd.to_datetime(datetime.today().strftime('%Y-%m-%d')):\n",
    "            print('Data already updated - Done')\n",
    "            return data\n",
    "        print('Data outdated: Downloading new data')\n",
    "        new_data = exponential_backoff(ticker, max_date)\n",
    "        new_data.columns = new_data.columns.str.replace(' ', '_')\n",
    "        data = data.loc[data.index != max_date]\n",
    "        print(data)\n",
    "        print(new_data)\n",
    "        data = data.append(new_data)\n",
    "        \n",
    "        data.columns = data.columns.str.replace(' ', '_')\n",
    "        add_to_history(ticker, data)\n",
    "        return data\n",
    "    \n",
    "    if not is_in_history(ticker):\n",
    "        print('Ticker \"{}\" not in Current Data, Downloading Fresh'.format(ticker))\n",
    "        data = exponential_backoff(ticker)\n",
    "        print('Downloaded!')\n",
    "        data.columns = data.columns.str.replace(' ', '_')\n",
    "        add_to_history(ticker, data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Fresh\n",
      "Downloading Updates\n"
     ]
    }
   ],
   "source": [
    "def progress_bar(i, left):\n",
    "        power_of_one_dot = 100/left\n",
    "        pos = int(power_of_one_dot * i)\n",
    "        bar = ''\n",
    "        for num in range(0, pos -1 ):\n",
    "            if num %2 == 0:\n",
    "                bar = bar + 'o'\n",
    "            if num %2 != 0:\n",
    "                bar = bar + 'O'             \n",
    "        bar = bar + '>'\n",
    "        for num in range(0, 100 - pos):\n",
    "            bar = bar + ' '\n",
    "        bar = bar + '| {:.2f} % \\nDone: {} Remaining: {}'.format(100 * i/left, i, left - i )\n",
    "        print(bar) \n",
    "        \n",
    "        \n",
    "def download_everything(ticker_list):\n",
    "\n",
    "    temp  = pd.DataFrame(index = ticker_list)\n",
    "    saved = pick.read_sql('SELECT * from symbol_info').set_index('Ticker')\n",
    "    saved['Last Updated'] = pd.to_datetime(saved['Last Updated'])\n",
    "\n",
    "    todo = []\n",
    "    for index in temp.index:\n",
    "        if index not in saved.index:\n",
    "            todo.append(index)\n",
    "    remaining = len(todo)\n",
    "    \n",
    "    print('Downloading Fresh')\n",
    "    for i,ticker in enumerate(todo):\n",
    "        progress_bar(i, remaining)\n",
    "        download_symbol(ticker)\n",
    "        clear_output(wait = True)\n",
    "\n",
    "    print('Downloading Updates')\n",
    "    today = datetime.today()\n",
    "        \n",
    "    \n",
    "download_everything(tickers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last Updated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KEX</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXPS</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AERI</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODC</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOSS</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAC</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRKR</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTR</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CINR</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMST</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHAC</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MHN</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOVN</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAND</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JYNT</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VCLT</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETN</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTES</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTR</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJV</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNOW</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLDX</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETX</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNSL</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NWE</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMDA</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPNT</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDOC</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBS</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDFS</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NWBI</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORIG</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GWW</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AYTU</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANC</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PXLW</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TWOU</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCF</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEP</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRBP</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NXP</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMPH</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEE</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTY</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROP</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HFGIC</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECOL</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDE</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HASI</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZN</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRCP</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHI</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUNO</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEIS</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSCF</th>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5417 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Last Updated\n",
       "Ticker             \n",
       "KEX      2018-01-24\n",
       "DXPS     2018-01-24\n",
       "AERI     2018-01-24\n",
       "FL       2018-01-24\n",
       "ODC      2018-01-24\n",
       "KOSS     2018-01-24\n",
       "NAC      2018-01-24\n",
       "BRKR     2018-01-24\n",
       "LSTR     2018-01-24\n",
       "CINR     2018-01-24\n",
       "HMST     2018-01-24\n",
       "BHAC     2018-01-24\n",
       "MHN      2018-01-24\n",
       "NOVN     2018-01-24\n",
       "LAND     2018-01-24\n",
       "RP       2018-01-24\n",
       "JYNT     2018-01-24\n",
       "VCLT     2018-01-24\n",
       "ETN      2018-01-24\n",
       "CL       2018-01-24\n",
       "NTES     2018-01-24\n",
       "MTR      2018-01-24\n",
       "NJV      2018-01-24\n",
       "DNOW     2018-01-24\n",
       "CLDX     2018-01-24\n",
       "ETX      2018-01-24\n",
       "KNSL     2018-01-24\n",
       "NWE      2018-01-24\n",
       "AMDA     2018-01-24\n",
       "LPNT     2018-01-24\n",
       "...             ...\n",
       "TDOC     2018-01-24\n",
       "EBS      2018-01-24\n",
       "PDFS     2018-01-24\n",
       "NWBI     2018-01-24\n",
       "ORIG     2018-01-24\n",
       "GWW      2018-01-24\n",
       "AYTU     2018-01-24\n",
       "DM       2018-01-24\n",
       "BANC     2018-01-24\n",
       "PXLW     2018-01-24\n",
       "TWOU     2018-01-24\n",
       "FCF      2018-01-24\n",
       "SEP      2018-01-24\n",
       "CRBP     2018-01-24\n",
       "NXP      2018-01-24\n",
       "KMPH     2018-01-24\n",
       "CEE      2018-01-24\n",
       "PTY      2018-01-24\n",
       "GSM      2018-01-24\n",
       "ROP      2018-01-24\n",
       "HFGIC    2018-01-24\n",
       "ECOL     2018-01-24\n",
       "CDE      2018-01-24\n",
       "HASI     2018-01-24\n",
       "AZN      2018-01-24\n",
       "PRCP     2018-01-24\n",
       "PHI      2018-01-24\n",
       "JUNO     2018-01-24\n",
       "AEIS     2018-01-24\n",
       "PSCF     2018-01-24\n",
       "\n",
       "[5417 rows x 1 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved = pick.read_sql('SELECT * from symbol_info').set_index('Ticker')\n",
    "saved['Last Updated'] = pd.to_datetime(saved['Last Updated'])\n",
    "saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_fix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oOoOo>                                                                                              | 6.77 % \n",
      "Done: 367 Remaining: 5050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-484a7af14e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_do\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_from_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mto_fix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-b2ae8c84372e>\u001b[0m in \u001b[0;36mload_from_history\u001b[1;34m(ticker, columns)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#if 'Date' not in columns:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#    columns.append('Date')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sql_tools\\__init__.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, table, columns, where, number)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSQL\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame(columns = tickers.index)\n",
    "to_do = len(data.columns)\n",
    "for i, column in enumerate(data.columns):\n",
    "    progress_bar(i,to_do )\n",
    "    try: \n",
    "        data[column] = load_from_history(column, ['Date', 'Close'])['Close']\n",
    "    except ValueError as e:\n",
    "        to_fix.append(column)\n",
    "        pass\n",
    "    clear_output(wait = True)\n",
    "raw_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEX', 'DXPS', 'AERI', 'FL', 'ODC', 'KOSS', 'NAC', 'BRKR', 'LSTR',\n",
       "       'CINR',\n",
       "       ...\n",
       "       'HFGIC', 'ECOL', 'CDE', 'HASI', 'AZN', 'PRCP', 'PHI', 'JUNO', 'AEIS',\n",
       "       'PSCF'],\n",
       "      dtype='object', name='Ticker', length=5417)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in to_fix:\n",
    "    x = load_from_history(column)\n",
    "    x = x[~x.index.duplicated()]\n",
    "    x.to_sql(column, con, if_exists= 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-0ea1b0318c85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mto_do\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_do\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   2346\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2348\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2350\u001b[0m             \u001b[1;31m# row-wise access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'log'"
     ]
    }
   ],
   "source": [
    "data = raw_data.copy()\n",
    "to_do = len(data.columns)\n",
    "for i, col in enumerate(data.columns):\n",
    "    data[col] = data[col].apply(np.log)\n",
    "    progress_bar(i, to_do)\n",
    "    clear_output(wait = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
